# Configuración del Servidor
APP_NAME="Analizador TDR SEACE"
APP_ENV=development
DEBUG=True
HOST=0.0.0.0
PORT=8001

# LLM por Defecto (gemini, openai, anthropic)
DEFAULT_LLM_PROVIDER=gemini

# Google Gemini API (2026 - Recomendado para volumen)
# Obtén tu API key en: https://aistudio.google.com/app/apikey
# Free Tier: 1,500 requests/día, 15 RPM, 1M tokens de contexto
# Modelos disponibles: gemini-pro, gemini-1.5-pro, gemini-1.5-pro-latest
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-pro

# OpenAI API (Opcional - Alternativa económica)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini

# Anthropic API (Opcional - Alternativa rápida)
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-5-haiku-20250122

# Configuración del RAG
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_CHUNKS=5

# Límites de procesamiento
MAX_FILE_SIZE_MB=10
REQUEST_TIMEOUT_SECONDS=60

# Procesamiento Asíncrono (para scraper que envía 3-10 docs cada 40 min)
# Con 36 rondas/día × 10 docs = 360 docs/día (24% del límite Free Tier)
MAX_CONCURRENT_REQUESTS=3
ENABLE_BATCH_PROCESSING=true
