"""
Cliente para Google Gemini API.
"""
import google.generativeai as genai
from typing import Dict
import logging
from .base_client import BaseLLMClient

logger = logging.getLogger(__name__)


class GeminiClient(BaseLLMClient):
    """
    Cliente para Google Gemini API (2026).
    Optimizado para Gemini 2.5/3 Flash con 1M tokens de contexto.
    Free Tier: 1,500 requests/d√≠a, 15 RPM.
    """

    def __init__(self, api_key: str, model_name: str):
        """El model_name debe venir desde settings.gemini_model"""
        self.api_key = api_key
        self.model_name = model_name
        self.logger = logger

        # Configurar Gemini
        genai.configure(api_key=api_key)

        # Configuraci√≥n de generaci√≥n (JSON mode sin schema - evita error "unhashable type: 'list'")
        self.generation_config = {
            "temperature": 0.2,  # M√°s determinista para JSON estructurado
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 8192,  # Aumentado para an√°lisis completos (antes: 3072)
            "response_mime_type": "application/json",  # Forzar JSON sin schema estricto
        }

        # Configuraci√≥n de seguridad (permitir todo para an√°lisis t√©cnico)
        self.safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]

        self.model = genai.GenerativeModel(
            model_name=model_name,
            generation_config=self.generation_config,
            safety_settings=self.safety_settings,
            system_instruction=self.SYSTEM_PROMPT
        )

    async def analyze_tdr(self, context: str) -> Dict:
        """
        Analiza el TDR usando Gemini 2.5/3 Flash con JSON Schema enforced.
        Ventana de contexto: 1M tokens.

        Args:
            context: Contexto del TDR recuperado por el RAG

        Returns:
            Dict con el an√°lisis estructurado
        """
        try:
            self.logger.info(f"Analizando TDR con Gemini ({self.model_name})")
            self.logger.debug(f"Contexto: {len(context)} caracteres")

            # Prompt simplificado (el schema ya define la estructura)
            user_prompt = f"""
Analiza este T√©rmino de Referencia del SEACE y extrae:

1. **Resumen ejecutivo**: Qu√© busca la entidad y qu√© se necesita para ganar (2-3 p√°rrafos)
2. **Requisitos t√©cnicos**: Certificaciones, experiencia, tecnolog√≠as requeridas
3. **Reglas de negocio**: Obligaciones, entregables, condiciones
4. **Penalidades**: Multas, garant√≠as, sanciones
5. **Presupuesto referencial**: Monto en soles o null
6. **Score de compatibilidad (1-10)**: Basado en claridad, viabilidad t√©cnica y riesgo

**TDR:**
{context}
"""

            # Generar respuesta con JSON Schema enforced
            response = await self.model.generate_content_async(user_prompt)

            # Gemini con response_schema devuelve JSON v√°lido directamente
            response_text = response.text.strip()

            self.logger.debug(f"Respuesta del LLM (primeros 500 chars): {response_text[:500]}")

            # Parsear JSON (debe ser v√°lido gracias al schema)
            result = self._parse_json_response(response_text)

            self.logger.info("‚úÖ An√°lisis completado exitosamente con Gemini")

            return result

        except Exception as e:
            self.logger.error(f"‚ùå Error al analizar con Gemini: {str(e)}")
            # Fallback: devolver an√°lisis b√°sico
            return {
                "resumen_ejecutivo": f"Error al analizar el TDR: {str(e)}. Contexto disponible: {len(context)} caracteres.",
                "requisitos_tecnicos": [],
                "reglas_de_negocio": [],
                "politicas_y_penalidades": [],
                "presupuesto_referencial": None,
                "score_compatibilidad": 1
            }

    async def analyze_tdr_from_pdf(self, pdf_bytes: bytes, filename: str) -> Dict:
        """
        Analiza un TDR enviando el PDF directamente a Gemini (sin extracci√≥n de texto).
        Gemini 2.5 Flash soporta PDFs nativamente con Vision integrada.
        Usa inline_data para evitar subir archivos a Files API.

        Args:
            pdf_bytes: Contenido binario del PDF
            filename: Nombre del archivo para logs

        Returns:
            Dict con el an√°lisis estructurado
        """
        try:
            self.logger.info(f"üìÑ Analizando PDF directo con Gemini ({self.model_name})")
            self.logger.info(f"   Archivo: {filename} ({len(pdf_bytes)} bytes)")

            # ESTRATEGIA: Inline data (sin Files API)
            self.logger.info("üì¶ Preparando PDF inline para Gemini...")

            import base64
            pdf_base64 = base64.b64encode(pdf_bytes).decode('utf-8')

            # Crear parte inline con el PDF
            pdf_part = {
                "inline_data": {
                    "mime_type": "application/pdf",
                    "data": pdf_base64
                }
            }

            self.logger.info(f"‚úÖ PDF preparado ({len(pdf_base64)} chars base64)")

            # Prompt para an√°lisis
            prompt = """
Analiza este TDR del SEACE (Per√∫) y extrae informaci√≥n clave en formato JSON compacto.

IMPORTANTE: Responde SOLO con JSON v√°lido, sin markdown, sin explicaciones adicionales.

Estructura requerida:
{
    "resumen_ejecutivo": "Texto de 100-200 palabras explicando: ¬øQu√© busca la entidad? ¬øAlcance? ¬øRequisitos clave?",
    "requisitos_tecnicos": ["Lista de certificaciones, experiencia, tecnolog√≠as, equipos requeridos"],
    "reglas_de_negocio": ["Lista de plazos, lugar, modalidad pago, garant√≠as, obligaciones"],
    "politicas_penalidades": ["Lista de multas, sanciones, porcentajes, causales"],
    "presupuesto_referencial": "S/ X,XXX.XX o null (sin comillas)",
    "score_compatibilidad": 7
}

REGLAS:
- Resumen ejecutivo: M√°ximo 200 palabras, enfocado en lo esencial
- Cada array: M√°ximo 10 items por lista
- Si no hay info: usar [] o null
- NO inventes datos
- Presupuesto: "S/ X,XXX.XX" exacto o null
- Score: 1-10 seg√∫n viabilidad

Devuelve √öNICAMENTE el JSON, sin ```json ni explicaciones.
"""

            # Analizar con el PDF inline
            self.logger.info("ü§ñ Enviando PDF inline a Gemini...")
            response = await self.model.generate_content_async([prompt, pdf_part])

            # Parsear respuesta
            response_text = response.text.strip()
            self.logger.debug(f"Respuesta (primeros 500 chars): {response_text[:500]}")

            result = self._parse_json_response(response_text)
            self.logger.info("‚úÖ An√°lisis PDF inline completado exitosamente")

            return result

        except Exception as e:
            self.logger.error(f"‚ùå Error al analizar PDF con Gemini: {str(e)}")
            raise ValueError(f"Error en an√°lisis PDF directo: {str(e)}")
